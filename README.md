# open-chat-llmops
Local LLM chat with MLflow observability.
